# Challenge Data Science 11/2022

Aceitei em participar deste desafio/projeto pois achei uma excelente oportunidade de colocar em prática o que venho estudando no últimos meses, simulando um projeto real.

| :placard: Vitrine.Dev |     |
| -------------  | --- |
| :sparkles: Nome        | **Insight Places**
| :label: Tecnologias | PySpark, BigData, Python, Machine Learning, Data Engineering
| :rocket: URL         | https://github.com/marcelinoandre/challengedatascience_2022_nov
| :fire: Desafio     | [Desafio](https://www.alura.com.br/challenges/data-science-2/semana-01-transformacao-dados-pyspark?utm_source=ActiveCampaign&utm_medium=email&utm_content=%5BChallenge+Data+Science%5D+Aula+01+Liberada%21&utm_campaign=%5BChallenges%5D+%28Dados+2a+ed+%29+Libera%C3%A7%C3%A3o+da+aula+01+%2B+convite+live+dive+coding&vgo_ee=m974RDr6G5JExwnAIqDaXAA3SuMkJhmkGexv49sZvNU%3D)

<!-- Inserir imagem com a #vitrinedev ao final do link -->
![](https://raw.githubusercontent.com/marcelinoandre/challengedatascience_2022_nov/main/resources/home_insigthplaces.png#vitrinedev)

## Detalhes do projeto

A imobiliária **InsightPlaces**, situada na cidade do Rio de Janeiro, está enfrentando dificuldades para alugar e vender imóveis. Em uma pesquisa de como empresas semelhantes operam no mercado, a InsightPlaces percebeu que esse problema pode estar relacionado aos valores dos imóveis e às recomendações que faz.

Sou do time de Ciência de Dados e **Big Data** da InsightPlaces e fiquei responsável por auxiliar no processo de análise de dados dos imóveis localizados em alguns bairros da cidade do Rio de Janeiro.

Dentro desse contexto, como podemos definir de forma eficiente os preços dos imóveis lidando com grande volume de dados? É importante recomendar imóveis utilizando outro critério? O que precisa ser feito?

Esse projeto tem algumas etapas como: ler e fazer o tratamento do histórico dos preços de imóveis no Rio de Janeiro, construir um modelo de regressão para precificar imóveis e criar um recomendador de imóveis. Para cada uma dessas etapas vamos utilizar a ferramenta **PySpark** que oferece uma melhor performance ao trabalharmos com grandes volumes de dado

Vamos que vamos!

## Etapas do projeto
### **SEMANA 01:**

Transformando dados com PySpark

Vamos explorar e tratar uma base de dados que veio dos sistemas internos da nossa empresa.
